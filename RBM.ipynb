{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Implement from scratch an RBM and apply it to DSET3. The RBM should be implemented fully by you (both CD-1 training and inference steps) but you are free to use library functions for the rest (e.g. image loading and management, etc.).\n",
    "\n",
    "1.     Train an RBM with a number of hidden neurons selected by you (single layer) on the MNIST data (use the training set split provided by the website).\n",
    "\n",
    "2.     Use the trained RBM to encode a selection of test images (e.g. using one per digit type) using the corresponding activation of the hidden neurons.\n",
    "\n",
    "3.    Train a simple classifier (e.g. any simple classifier in scikit) to recognize the MNIST digits using as inputs their encoding obtained at step 2. Use the standard training/test split. Show a performance metric of your choice in the presentation/handout."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "import tensorflow\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from keras.datasets import mnist\n",
    "\n",
    "(Xtr, ytr), (Xts, yts) = mnist.load_data()\n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[254 106   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0  83 253 209  18   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0]\n",
      "[0.99607843 0.41568627 0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.3254902  0.99215686 0.81960784 0.07058824\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.        ]\n"
     ]
    }
   ],
   "source": [
    "Xtr_flat = Xtr.reshape(Xtr.shape[0],-1)\n",
    "Xts_flat = Xts.reshape(Xts.shape[0],-1)\n",
    "print(Xts_flat[0,300:350])\n",
    "\n",
    "#i was having exploding gradient, so i normalized in this way\n",
    "Xts_flat = Xts_flat / 255\n",
    "Xtr_flat = Xtr_flat / 255\n",
    "print(Xts_flat[0,300:350])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RBM is composed by the nodes (hidden and visible) and the links between the nodes (the weights matrix) + bias\n",
    "class RBM:\n",
    "    def __init__(self, v_num, h_num):\n",
    "        # number of visible variables\n",
    "        self.v_num = v_num\n",
    "        # number of hidden variables\n",
    "        self.h_num = h_num\n",
    "        # value of the weights\n",
    "        self.weights = np.random.randn(v_num, h_num) * 0.1\n",
    "        # bias\n",
    "        self.v_bias = np.zeros(v_num)\n",
    "        self.h_bias = np.zeros(h_num)\n",
    "\n",
    "    def wake_phase(self, v_prob):\n",
    "        # dot product between v_prob (which will be the data) and the weights, then add the bias\n",
    "        h_activations = np.dot(v_prob, self.weights) + self.h_bias\n",
    "        # compute activation\n",
    "        h_probabilities = sigmoid(h_activations)\n",
    "        return h_probabilities, np.random.binomial(1, h_probabilities)\n",
    "\n",
    "    def dream_phase(self, h_prob):\n",
    "        # dot product between h_prob and the transpose of the weights, then add the bias\n",
    "        v_activations = np.dot(h_prob, self.weights.T) + self.v_bias\n",
    "        # compute activation\n",
    "        v_probabilities = sigmoid(v_activations)\n",
    "        return v_probabilities, np.random.binomial(1, v_probabilities)\n",
    "\n",
    "    # training cycle, inputs are: the dataset, the number of epochs, the batch size, the learning rate and the number of contrastive\n",
    "    # divergence steps\n",
    "    def train(self, data, num_epochs=10, batch_size=10, lr = 0.1, cd_steps = 1):\n",
    "\n",
    "        num_examples = data.shape[0]\n",
    "\n",
    "        for _ in range(num_epochs):\n",
    "            # iterate starting from the first image on the entire dataset, moving the index according to batch_size\n",
    "            for i in range(0, num_examples, batch_size):\n",
    "                # i take 'batch_size' number of images\n",
    "                batch = data[i:i + batch_size]\n",
    "\n",
    "                # Contrastive divergence\n",
    "                h_probabilities, positive_hidden = self.wake_phase(batch)\n",
    "                for _ in range(cd_steps):\n",
    "                    _, visible_states = self.dream_phase(positive_hidden)\n",
    "                    hidden_prob, hidden_states = self.wake_phase(visible_states)\n",
    "\n",
    "                # Update weights and biases\n",
    "                visible_associations = np.dot(batch.T, h_probabilities)\n",
    "                hidden_associations = np.dot(visible_states.T, hidden_states)\n",
    "\n",
    "                # we try to reach equilibrium, so we want the difference to be closer as possible to zero\n",
    "                self.weights += lr * ((visible_associations - hidden_associations) / batch_size)\n",
    "                self.v_bias += lr * np.mean(batch - visible_states, axis=0)\n",
    "                self.h_bias += lr * np.mean(h_probabilities - hidden_prob, axis=0)\n",
    "\n",
    "    def generate(self, data, k=1):\n",
    "        samples = np.copy(data)\n",
    "        for i in range(len(samples)):\n",
    "            visible = samples[i]\n",
    "            for _ in range(k):  # Gibbs sampling steps\n",
    "                hidden_prob, hidden = self.wake_phase(visible)\n",
    "                visible_prob, visible = self.dream_phase(hidden)\n",
    "            samples[i] = visible\n",
    "        return samples\n",
    "\n",
    "def sigmoid(x):\n",
    "    return 1 / (1 + np.exp(-x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(64, 784)\n",
      "(64, 300)\n",
      "(64, 784)\n",
      "(64, 300)\n",
      "(64, 784)\n",
      "(64, 300)\n",
      "(64, 784)\n",
      "(64, 300)\n",
      "(64, 784)\n",
      "(64, 300)\n",
      "(64, 784)\n",
      "(64, 300)\n",
      "(64, 784)\n",
      "(64, 300)\n",
      "(64, 784)\n",
      "(64, 300)\n",
      "(64, 784)\n",
      "(64, 300)\n",
      "(64, 784)\n",
      "(64, 300)\n",
      "(64, 784)\n",
      "(64, 300)\n",
      "(64, 784)\n",
      "(64, 300)\n",
      "(64, 784)\n",
      "(64, 300)\n",
      "(64, 784)\n",
      "(64, 300)\n",
      "(64, 784)\n",
      "(64, 300)\n",
      "(64, 784)\n",
      "(64, 300)\n",
      "(64, 784)\n",
      "(64, 300)\n",
      "(64, 784)\n",
      "(64, 300)\n",
      "(64, 784)\n",
      "(64, 300)\n",
      "(64, 784)\n",
      "(64, 300)\n",
      "(64, 784)\n",
      "(64, 300)\n",
      "(64, 784)\n",
      "(64, 300)\n",
      "(64, 784)\n",
      "(64, 300)\n",
      "(64, 784)\n",
      "(64, 300)\n",
      "(64, 784)\n",
      "(64, 300)\n",
      "(64, 784)\n",
      "(64, 300)\n",
      "(64, 784)\n",
      "(64, 300)\n",
      "(64, 784)\n",
      "(64, 300)\n",
      "(64, 784)\n",
      "(64, 300)\n",
      "(64, 784)\n",
      "(64, 300)\n",
      "(64, 784)\n",
      "(64, 300)\n",
      "(64, 784)\n",
      "(64, 300)\n",
      "(64, 784)\n",
      "(64, 300)\n",
      "(64, 784)\n",
      "(64, 300)\n",
      "(64, 784)\n",
      "(64, 300)\n",
      "(64, 784)\n",
      "(64, 300)\n",
      "(64, 784)\n",
      "(64, 300)\n",
      "(64, 784)\n",
      "(64, 300)\n",
      "(64, 784)\n",
      "(64, 300)\n",
      "(64, 784)\n",
      "(64, 300)\n",
      "(64, 784)\n",
      "(64, 300)\n",
      "(64, 784)\n",
      "(64, 300)\n",
      "(64, 784)\n",
      "(64, 300)\n",
      "(64, 784)\n",
      "(64, 300)\n",
      "(64, 784)\n",
      "(64, 300)\n",
      "(64, 784)\n",
      "(64, 300)\n",
      "(64, 784)\n",
      "(64, 300)\n",
      "(64, 784)\n",
      "(64, 300)\n",
      "(64, 784)\n",
      "(64, 300)\n",
      "(64, 784)\n",
      "(64, 300)\n",
      "(64, 784)\n",
      "(64, 300)\n",
      "(64, 784)\n",
      "(64, 300)\n",
      "(64, 784)\n",
      "(64, 300)\n",
      "(64, 784)\n",
      "(64, 300)\n",
      "(64, 784)\n",
      "(64, 300)\n",
      "(64, 784)\n",
      "(64, 300)\n",
      "(64, 784)\n",
      "(64, 300)\n",
      "(64, 784)\n",
      "(64, 300)\n",
      "(64, 784)\n",
      "(64, 300)\n",
      "(64, 784)\n",
      "(64, 300)\n",
      "(64, 784)\n",
      "(64, 300)\n",
      "(64, 784)\n",
      "(64, 300)\n",
      "(64, 784)\n",
      "(64, 300)\n",
      "(64, 784)\n",
      "(64, 300)\n",
      "(64, 784)\n",
      "(64, 300)\n",
      "(64, 784)\n",
      "(64, 300)\n",
      "(64, 784)\n",
      "(64, 300)\n",
      "(64, 784)\n",
      "(64, 300)\n",
      "(64, 784)\n",
      "(64, 300)\n",
      "(64, 784)\n",
      "(64, 300)\n",
      "(64, 784)\n",
      "(64, 300)\n",
      "(64, 784)\n",
      "(64, 300)\n",
      "(64, 784)\n",
      "(64, 300)\n",
      "(64, 784)\n",
      "(64, 300)\n",
      "(64, 784)\n",
      "(64, 300)\n",
      "(64, 784)\n",
      "(64, 300)\n",
      "(64, 784)\n",
      "(64, 300)\n",
      "(64, 784)\n",
      "(64, 300)\n",
      "(64, 784)\n",
      "(64, 300)\n",
      "(64, 784)\n",
      "(64, 300)\n",
      "(64, 784)\n",
      "(64, 300)\n",
      "(64, 784)\n",
      "(64, 300)\n",
      "(64, 784)\n",
      "(64, 300)\n",
      "(64, 784)\n",
      "(64, 300)\n",
      "(64, 784)\n",
      "(64, 300)\n",
      "(64, 784)\n",
      "(64, 300)\n",
      "(64, 784)\n",
      "(64, 300)\n",
      "(64, 784)\n",
      "(64, 300)\n",
      "(64, 784)\n",
      "(64, 300)\n",
      "(64, 784)\n",
      "(64, 300)\n",
      "(64, 784)\n",
      "(64, 300)\n",
      "(64, 784)\n",
      "(64, 300)\n",
      "(64, 784)\n",
      "(64, 300)\n",
      "(64, 784)\n",
      "(64, 300)\n",
      "(64, 784)\n",
      "(64, 300)\n",
      "(64, 784)\n",
      "(64, 300)\n",
      "(64, 784)\n",
      "(64, 300)\n",
      "(64, 784)\n",
      "(64, 300)\n",
      "(64, 784)\n",
      "(64, 300)\n",
      "(64, 784)\n",
      "(64, 300)\n",
      "(64, 784)\n",
      "(64, 300)\n",
      "(64, 784)\n",
      "(64, 300)\n",
      "(64, 784)\n",
      "(64, 300)\n",
      "(64, 784)\n",
      "(64, 300)\n",
      "(64, 784)\n",
      "(64, 300)\n",
      "(64, 784)\n",
      "(64, 300)\n",
      "(64, 784)\n",
      "(64, 300)\n",
      "(64, 784)\n",
      "(64, 300)\n",
      "(64, 784)\n",
      "(64, 300)\n",
      "(64, 784)\n",
      "(64, 300)\n",
      "(64, 784)\n",
      "(64, 300)\n",
      "(64, 784)\n",
      "(64, 300)\n",
      "(64, 784)\n",
      "(64, 300)\n",
      "(64, 784)\n",
      "(64, 300)\n",
      "(64, 784)\n",
      "(64, 300)\n",
      "(64, 784)\n",
      "(64, 300)\n",
      "(64, 784)\n",
      "(64, 300)\n",
      "(64, 784)\n",
      "(64, 300)\n",
      "(64, 784)\n",
      "(64, 300)\n",
      "(64, 784)\n",
      "(64, 300)\n",
      "(64, 784)\n",
      "(64, 300)\n",
      "(64, 784)\n",
      "(64, 300)\n",
      "(64, 784)\n",
      "(64, 300)\n",
      "(64, 784)\n",
      "(64, 300)\n",
      "(64, 784)\n",
      "(64, 300)\n",
      "(64, 784)\n",
      "(64, 300)\n",
      "(64, 784)\n",
      "(64, 300)\n",
      "(64, 784)\n",
      "(64, 300)\n",
      "(64, 784)\n",
      "(64, 300)\n",
      "(64, 784)\n",
      "(64, 300)\n",
      "(64, 784)\n",
      "(64, 300)\n",
      "(64, 784)\n",
      "(64, 300)\n",
      "(64, 784)\n",
      "(64, 300)\n",
      "(64, 784)\n",
      "(64, 300)\n",
      "(64, 784)\n",
      "(64, 300)\n",
      "(64, 784)\n",
      "(64, 300)\n",
      "(64, 784)\n",
      "(64, 300)\n",
      "(64, 784)\n",
      "(64, 300)\n",
      "(64, 784)\n",
      "(64, 300)\n",
      "(64, 784)\n",
      "(64, 300)\n",
      "(64, 784)\n",
      "(64, 300)\n",
      "(64, 784)\n",
      "(64, 300)\n",
      "(64, 784)\n",
      "(64, 300)\n",
      "(64, 784)\n",
      "(64, 300)\n",
      "(64, 784)\n",
      "(64, 300)\n",
      "(64, 784)\n",
      "(64, 300)\n",
      "(64, 784)\n",
      "(64, 300)\n",
      "(64, 784)\n",
      "(64, 300)\n",
      "(64, 784)\n",
      "(64, 300)\n",
      "(64, 784)\n",
      "(64, 300)\n",
      "(64, 784)\n",
      "(64, 300)\n",
      "(64, 784)\n",
      "(64, 300)\n",
      "(64, 784)\n",
      "(64, 300)\n",
      "(64, 784)\n",
      "(64, 300)\n",
      "(64, 784)\n",
      "(64, 300)\n",
      "(64, 784)\n",
      "(64, 300)\n",
      "(64, 784)\n",
      "(64, 300)\n",
      "(64, 784)\n",
      "(64, 300)\n",
      "(64, 784)\n",
      "(64, 300)\n",
      "(64, 784)\n",
      "(64, 300)\n",
      "(64, 784)\n",
      "(64, 300)\n",
      "(64, 784)\n",
      "(64, 300)\n",
      "(64, 784)\n",
      "(64, 300)\n",
      "(64, 784)\n",
      "(64, 300)\n",
      "(64, 784)\n",
      "(64, 300)\n",
      "(64, 784)\n",
      "(64, 300)\n",
      "(64, 784)\n",
      "(64, 300)\n",
      "(64, 784)\n",
      "(64, 300)\n",
      "(64, 784)\n",
      "(64, 300)\n",
      "(64, 784)\n",
      "(64, 300)\n",
      "(64, 784)\n",
      "(64, 300)\n",
      "(64, 784)\n",
      "(64, 300)\n",
      "(64, 784)\n",
      "(64, 300)\n",
      "(64, 784)\n",
      "(64, 300)\n",
      "(64, 784)\n",
      "(64, 300)\n",
      "(64, 784)\n",
      "(64, 300)\n",
      "(64, 784)\n",
      "(64, 300)\n",
      "(64, 784)\n",
      "(64, 300)\n",
      "(64, 784)\n",
      "(64, 300)\n",
      "(64, 784)\n",
      "(64, 300)\n",
      "(64, 784)\n",
      "(64, 300)\n",
      "(64, 784)\n",
      "(64, 300)\n",
      "(64, 784)\n",
      "(64, 300)\n",
      "(64, 784)\n",
      "(64, 300)\n",
      "(64, 784)\n",
      "(64, 300)\n",
      "(64, 784)\n",
      "(64, 300)\n",
      "(64, 784)\n",
      "(64, 300)\n",
      "(64, 784)\n",
      "(64, 300)\n",
      "(64, 784)\n",
      "(64, 300)\n",
      "(64, 784)\n",
      "(64, 300)\n",
      "(64, 784)\n",
      "(64, 300)\n",
      "(64, 784)\n",
      "(64, 300)\n",
      "(64, 784)\n",
      "(64, 300)\n",
      "(64, 784)\n",
      "(64, 300)\n",
      "(64, 784)\n",
      "(64, 300)\n",
      "(64, 784)\n",
      "(64, 300)\n",
      "(64, 784)\n",
      "(64, 300)\n",
      "(64, 784)\n",
      "(64, 300)\n",
      "(64, 784)\n",
      "(64, 300)\n",
      "(64, 784)\n",
      "(64, 300)\n",
      "(64, 784)\n",
      "(64, 300)\n",
      "(64, 784)\n",
      "(64, 300)\n",
      "(64, 784)\n",
      "(64, 300)\n",
      "(64, 784)\n",
      "(64, 300)\n",
      "(64, 784)\n",
      "(64, 300)\n",
      "(64, 784)\n",
      "(64, 300)\n",
      "(64, 784)\n",
      "(64, 300)\n",
      "(64, 784)\n",
      "(64, 300)\n",
      "(64, 784)\n",
      "(64, 300)\n",
      "(64, 784)\n",
      "(64, 300)\n",
      "(64, 784)\n",
      "(64, 300)\n",
      "(64, 784)\n",
      "(64, 300)\n",
      "(64, 784)\n",
      "(64, 300)\n",
      "(64, 784)\n",
      "(64, 300)\n",
      "(64, 784)\n",
      "(64, 300)\n",
      "(64, 784)\n",
      "(64, 300)\n",
      "(64, 784)\n",
      "(64, 300)\n",
      "(64, 784)\n",
      "(64, 300)\n",
      "(64, 784)\n",
      "(64, 300)\n",
      "(64, 784)\n",
      "(64, 300)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[10], line 5\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# from sklearn.metrics import mean_squared_error\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \n\u001b[0;32m      3\u001b[0m \u001b[38;5;66;03m# Initialize and train RBM\u001b[39;00m\n\u001b[0;32m      4\u001b[0m rbm \u001b[38;5;241m=\u001b[39m RBM(v_num\u001b[38;5;241m=\u001b[39mXtr_flat\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m], h_num\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m300\u001b[39m)\n\u001b[1;32m----> 5\u001b[0m \u001b[43mrbm\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mXtr_flat\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_epochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m64\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[9], line 44\u001b[0m, in \u001b[0;36mRBM.train\u001b[1;34m(self, data, num_epochs, batch_size, lr, cd_steps)\u001b[0m\n\u001b[0;32m     42\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m _ \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(cd_steps):\n\u001b[0;32m     43\u001b[0m     _, visible_states \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdream_phase(positive_hidden)\n\u001b[1;32m---> 44\u001b[0m     hidden_prob, hidden_states \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwake_phase\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvisible_states\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     46\u001b[0m \u001b[38;5;66;03m# Update weights and biases\u001b[39;00m\n\u001b[0;32m     47\u001b[0m visible_associations \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mdot(batch\u001b[38;5;241m.\u001b[39mT, h_probabilities)\n",
      "Cell \u001b[1;32mIn[9], line 19\u001b[0m, in \u001b[0;36mRBM.wake_phase\u001b[1;34m(self, v_prob)\u001b[0m\n\u001b[0;32m     17\u001b[0m \u001b[38;5;66;03m# compute activation\u001b[39;00m\n\u001b[0;32m     18\u001b[0m h_probabilities \u001b[38;5;241m=\u001b[39m sigmoid(h_activations)\n\u001b[1;32m---> 19\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m h_probabilities, np\u001b[38;5;241m.\u001b[39mrandom\u001b[38;5;241m.\u001b[39mbinomial(\u001b[38;5;241m1\u001b[39m, h_probabilities)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# from sklearn.metrics import mean_squared_error\n",
    "\n",
    "# Initialize and train RBM\n",
    "rbm = RBM(v_num=Xtr_flat.shape[1], h_num=300)\n",
    "rbm.train(Xtr_flat, num_epochs=1,batch_size=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Fede\\AppData\\Local\\Temp\\ipykernel_16580\\1277780296.py:66: RuntimeWarning: overflow encountered in exp\n",
      "  return 1 / (1 + np.exp(-x))\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 2000x400 with 20 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "test_data = Xts.reshape(Xts.shape[0],-1)\n",
    "\n",
    "\n",
    "def plot_images(original_images, reconstructed_images, num_images=10):\n",
    "    plt.figure(figsize=(20, 4))\n",
    "    for i in range(num_images):\n",
    "        # Original image\n",
    "        plt.subplot(2, num_images, i + 1)\n",
    "        plt.imshow(original_images[i].reshape(28, 28), cmap='gray')\n",
    "        plt.title(\"MNIST\")\n",
    "        plt.axis('off')\n",
    "\n",
    "        # Reconstructed image\n",
    "        plt.subplot(2, num_images, i + 1 + num_images)\n",
    "        plt.imshow(reconstructed_images[i].reshape(28, 28), cmap='gray')\n",
    "        plt.title(\"RBM\")\n",
    "        plt.axis('off')\n",
    "    plt.show()\n",
    "\n",
    "# Assuming test_data contains original images and visible_prob contains reconstructions\n",
    "num_images_to_plot = 10  # Number of images you want to plot\n",
    "\n",
    "visible_prob= rbm.generate(test_data[:num_images_to_plot], 1)\n",
    "\n",
    "# Plot original and reconstructed images in cycles of 10, up to num_images_to_plot\n",
    "for i in range(0, num_images_to_plot, 10):\n",
    "    plot_images(test_data[i:i + 10], visible_prob[i:i + 10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.random.binomial(1, 0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.99607843, 0.41568627, 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.3254902 , 0.99215686, 0.81960784, 0.07058824,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Xts_flat[0,300:350]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
